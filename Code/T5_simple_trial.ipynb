{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (['Four older adults are sitting in the back yard, watching a toddler who is standing near them.', \n",
    "      'Young girl in pink hat eating a meal of bread, fruits, and vegetables.',\n",
    "      'A girl is smiling while swinging on a swing',\n",
    "      'An older man sitting with a young boy in a hat.',\n",
    "      'The grandfather feeds his granddaughter as the rest of the family looks on.'],\n",
    "     \"The adults sat in their lawn chairs supervising the children. My niece had some of her favorite food to eat, including fruits. She went to play on her new swing set after eating. My nephew happily kept my uncle company. Today was my niece's birthday so we went over to celebrate.\"),\n",
    "     (['A large building that has been restored sitting against a clear sky.',\n",
    "   'A picture of buildings with Chinese architecture. The area seems to be relatively empty except for a few people in the distance, and the sky is clear.',\n",
    "   'What a wonderful looking building, very different and unique.',\n",
    "   'A column lined path leads to a temple',\n",
    "   'Asian garden with fox statue, lantern, gates and trees'],\n",
    "  'They used such distinctive architecture and paid so much attention to details. Our trip to Japan was amazing. We got to see how they built their temples. Even the steps leading up to the temples were cool. They were lined with statues that all had important meanings behind them.'),\n",
    " (['The man is wearing a red cap and is participating in a marathon.',\n",
    "   'Runner number 1212 walks through the airport with his bag over his shoulder before the race.',\n",
    "   'Two people are giving one another a high five.',\n",
    "   'A man in a white t-shirt stands behind a group of people who have a glass ceiling above them.',\n",
    "   'A group of runners taking a group photo.'],\n",
    "  'There was a real atmosphere of eagerness. Many of the runners were excellent athletes. But regardless of skill everyone there had fun. All the runners were excited to help a good cause. Some group photos would forever commemorate the event.')\n",
    "     ]\n",
    "\n",
    "def prepare_data(data):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for captions, story in data:\n",
    "        input_text = ' [SEP] '.join(captions)\n",
    "        inputs.append(input_text)\n",
    "        outputs.append(story)\n",
    "    return inputs, outputs\n",
    "\n",
    "train_inputs1, train_outputs1 = prepare_data([train_data[0]])\n",
    "train_inputs2, train_outputs2 = prepare_data([train_data[1]])\n",
    "train_inputs3, train_outputs3 = prepare_data([train_data[2]])\n",
    "all_train_inputs = [train_inputs1,train_inputs2,train_inputs3]\n",
    "all_train_outputs = [train_outputs1,train_outputs2,train_outputs3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "train_encodings = [tokenizer(train_inputs, padding=True, truncation=True, return_tensors=\"pt\") for train_inputs in all_train_inputs]\n",
    "train_labels = [tokenizer(train_outputs, padding=True, truncation=True, return_tensors=\"pt\").input_ids for train_outputs in all_train_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[   71,   508,   740,    24,    65,   118, 13216,  3823,   581,     3,\n",
      "              9,   964,  5796,     5,   784,   134,  8569,   908,    71,  1554,\n",
      "             13,  3950,    28,  2830,  4648,     5,    37,   616,  1330,    12,\n",
      "             36,  4352,  6364,  3578,    21,     3,     9,   360,   151,    16,\n",
      "              8,  2357,     6,    11,     8,  5796,    19,   964,     5,   784,\n",
      "            134,  8569,   908,   363,     3,     9,  1627,   479,   740,     6,\n",
      "            182,   315,    11,   775,     5,   784,   134,  8569,   908,    71,\n",
      "           6710, 14372,  2071,  3433,    12,     3,     9,  7657,   784,   134,\n",
      "           8569,   908,  6578,  2004,    28,     3, 20400, 12647,     6, 24167,\n",
      "              6, 18975,    11,  3124,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1]]]), 'labels': tensor([[[  328,   261,   224, 11562,  4648,    11,  1866,    78,   231,  1388,\n",
      "             12,  1030,     5,   421,  1469,    12,  3411,    47,  1237,     5,\n",
      "            101,   530,    12,   217,   149,    79,  1192,    70,  7657,     7,\n",
      "              5,  1441,     8,  2245,  1374,    95,    12,     8,  7657,     7,\n",
      "            130,  1633,     5,   328,   130, 14372,    28, 12647,     7,    24,\n",
      "             66,   141,   359,  2530,     7,  1187,   135,     5,     1]]])}\n",
      "{'input_ids': tensor([[[   37,   388,    19,  5119,     3,     9,  1131,  2468,    11,    19,\n",
      "           7448,    16,     3,     9, 17625,     5,   784,   134,  8569,   908,\n",
      "              3, 23572,   381,   586,  2122, 10681,   190,     8,  3761,    28,\n",
      "            112,  2182,   147,   112,  8173,   274,     8,  1964,     5,   784,\n",
      "            134,  8569,   908,  2759,   151,    33,  1517,    80,   430,     3,\n",
      "              9,   306,   874,     5,   784,   134,  8569,   908,    71,   388,\n",
      "             16,     3,     9,   872,     3,    17,    18,  9486,  5024,  1187,\n",
      "              3,     9,   563,    13,   151,   113,    43,     3,     9,  1905,\n",
      "           5020,   756,   135,     5,   784,   134,  8569,   908,    71,   563,\n",
      "             13, 16448,   838,     3,     9,   563,  1202,     5,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1]]]), 'labels': tensor([[[  290,    47,     3,     9,   490,  4643,    13, 10876,   655,     5,\n",
      "           1404,    13,     8, 16448,   130,  1287,  9227,     5,   299,  6147,\n",
      "             13,  4359,   921,   132,   141,   694,     5,   432,     8, 16448,\n",
      "            130,  2787,    12,   199,     3,     9,   207,  1137,     5,   886,\n",
      "            563,  1302,   133,  6276, 18681,    15,     8,   605,     5,     1]]])}\n",
      "{'input_ids': tensor([[[ 5933,  2749,  3513,    33,  3823,    16,     8,   223,  6178,     6,\n",
      "           3355,     3,     9, 13817,   113,    19,  4125,  1084,   135,     5,\n",
      "            784,   134,  8569,   908,  5209,  3202,    16,  5571,     3,   547,\n",
      "           3182,     3,     9,  3506,    13,  4109,     6,  6533,     6,    11,\n",
      "           6205,     5,   784,   134,  8569,   908,    71,  3202,    19, 20770,\n",
      "            298,  7180,    53,    30,     3,     9,  7180,   784,   134,  8569,\n",
      "            908,   389,  2749,   388,  3823,    28,     3,     9,  1021,  4940,\n",
      "             16,     3,     9,     3,   547,     5,   784,   134,  8569,   908,\n",
      "             37, 18573,  3305,     7,   112, 30963,    38,     8,   880,    13,\n",
      "              8,   384,  1416,    30,     5,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1]]]), 'labels': tensor([[[   37,  3513,     3,     7,   144,    16,    70,  8652,  6406,  1355,\n",
      "           3466,    53,     8,   502,     5,   499, 23642,   141,   128,    13,\n",
      "            160,  1305,   542,    12,     3,  1544,     6,   379,  6533,     5,\n",
      "            451,   877,    12,   577,    30,   160,   126,  7180,   356,   227,\n",
      "           3182,     5,   499, 23213, 16725,  2697,    82, 20811,   349,     5,\n",
      "           1960,    47,    82, 23642,    31,     7,  3591,    78,    62,   877,\n",
      "            147,    12,  4036,     5,     1]]])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val.clone().detach() for key, val in self.encodings[idx].items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = StoryDataset(train_encodings, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for btch in train_loader:\n",
    "    print(btch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.train()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed with loss: 0.018168499693274498\n",
      "Epoch 1 completed with loss: 0.017402423545718193\n",
      "Epoch 2 completed with loss: 0.021405942738056183\n",
      "Epoch 3 completed with loss: 0.008466326631605625\n",
      "Epoch 4 completed with loss: 0.019594982266426086\n",
      "Epoch 5 completed with loss: 0.008092958480119705\n",
      "Epoch 6 completed with loss: 0.01446730550378561\n",
      "Epoch 7 completed with loss: 0.014023566618561745\n",
      "Epoch 8 completed with loss: 0.007621606346219778\n",
      "Epoch 9 completed with loss: 0.013131316751241684\n",
      "Epoch 10 completed with loss: 0.007378798443824053\n",
      "Epoch 11 completed with loss: 0.012347742915153503\n",
      "Epoch 12 completed with loss: 0.013710255734622478\n",
      "Epoch 13 completed with loss: 0.011672087013721466\n",
      "Epoch 14 completed with loss: 0.006939155049622059\n",
      "Epoch 15 completed with loss: 0.012357023544609547\n",
      "Epoch 16 completed with loss: 0.011987525969743729\n",
      "Epoch 17 completed with loss: 0.01163025014102459\n",
      "Epoch 18 completed with loss: 0.010244892910122871\n",
      "Epoch 19 completed with loss: 0.01094258762896061\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        input_ids = input_ids.squeeze(1)\n",
    "        attention_mask = attention_mask.squeeze(1)\n",
    "        labels = labels.squeeze(1)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch} completed with loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no way to get to the lake from here but it has a great view. My niece had some of her favorite things to do with the lake. She went to see how she got to see her. She went to see her niece. She went to see her niece. She went to see her niece niece.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "new_captions = [\"you cant get to the lake from here but it is a great view\",\n",
    "   'A field that is near the waters of the beach.',\n",
    "   'A tree in the forest has fallen over on the grass.',\n",
    "   'A large group of deciduous trees are behind a grassy field.',\n",
    "   'People walking down a hill with a bunch of animals on it.']\n",
    "\n",
    "input_text = ' [SEP] '.join(new_captions)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate narrative story\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(input_ids, max_length=200)\n",
    "story = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
