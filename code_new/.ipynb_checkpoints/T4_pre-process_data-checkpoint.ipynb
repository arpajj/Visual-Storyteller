{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594a6f5d-82cb-4ebe-b9ba-88e47d1d543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle\n",
    "import numpy as np\n",
    "import string, torch, re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965e9107-f1a8-4ac8-9010-ccd131b7a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problematic_entries(dataset):\n",
    "    problematic_keys = []\n",
    "    for key, text in list(dataset.items())[:-1]:\n",
    "        if len(text[0])<5 or len(text[1])<5: \n",
    "            if len(text[0])<5:\n",
    "                problematic_keys.append(key)\n",
    "            if len(text[1])<5:\n",
    "                problematic_keys.append(key)\n",
    "    return problematic_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c737e802-64dc-40ec-b334-a3e42c0cd43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The non-five entries on the train dataset are: 278\n",
      "The precentage of these entires over the train dataset is 1.04% \n",
      "\n",
      "The non-five entries on the validation dataset are: 26\n",
      "The precentage of these entires over the validation dataset is 0.78% \n",
      "\n",
      "The non-five entries on the test dataset are: 20\n",
      "The precentage of these entires over the test dataset is 0.6%\n"
     ]
    }
   ],
   "source": [
    "phase2_path_train = '/data/admitosstorage/Phase_2/data_phase2/train_dataset_all_v1.json'\n",
    "phase2_path_val = '/data/admitosstorage/Phase_2/data_phase2/val_dataset_all_v1.json'\n",
    "phase2_path_test = '/data/admitosstorage/Phase_2/data_phase2/test_dataset_all_v1.json'\n",
    "\n",
    "with open(phase2_path_train, 'r', encoding='utf-8') as f:\n",
    "    #train_dataset = json.load(f) \n",
    "    train_dataset = dict(list(json.load(f).items())[:-1]) # We dont want to load the title \n",
    "\n",
    "with open(phase2_path_val, 'r', encoding='utf-8') as f:\n",
    "    #val_dataset = json.load(f)\n",
    "    val_dataset = dict(list(json.load(f).items())[:-1]) # We dont want to load the title \n",
    "\n",
    "with open(phase2_path_test, 'r', encoding='utf-8') as f:\n",
    "    #test_dataset = json.load(f)\n",
    "    test_dataset = dict(list(json.load(f).items())[:-1]) # We dont want to load the title  \n",
    "\n",
    "print(\"The non-five entries on the train dataset are: \", end=\"\")\n",
    "print(len(find_problematic_entries(train_dataset)))\n",
    "print(f'The precentage of these entires over the train dataset is {np.round(len(find_problematic_entries(train_dataset))/len(train_dataset)*100, 2)}% \\n')\n",
    "\n",
    "print(\"The non-five entries on the validation dataset are: \", end=\"\")\n",
    "print(len(find_problematic_entries(val_dataset)))\n",
    "print(f'The precentage of these entires over the validation dataset is {np.round(len(find_problematic_entries(val_dataset))/len(val_dataset)*100, 2)}% \\n')\n",
    "\n",
    "print(\"The non-five entries on the test dataset are: \", end=\"\")\n",
    "print(len(find_problematic_entries(test_dataset)))\n",
    "print(f'The precentage of these entires over the test dataset is {np.round(len(find_problematic_entries(test_dataset))/len(test_dataset)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e953ff-6337-4bea-9a58-64a8e73cb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709\n",
      "3332\n",
      "3348\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fafb39-5dc8-4fbc-8de4-045d8bdfe44d",
   "metadata": {},
   "source": [
    "### Combine all story sentences in a paragraph (Yingjin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de5f786-30c3-40e7-ac29-5530c82fb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lengths are equal.\n",
      "All lengths are equal.\n",
      "All lengths are equal.\n"
     ]
    }
   ],
   "source": [
    "def combine_sent_stories(old_dataset, choose_cap=0, verbose=False):\n",
    "    if choose_cap!=0 and choose_cap!=1 and choose_cap!=2:\n",
    "        raise ValueError(\"Not valid index for captions choosen\")\n",
    "    source_inputs = [value[0] for value in old_dataset.values()]\n",
    "    sent_targets = [value[1] for value in old_dataset.values()]\n",
    "    # choose the first of the three captions (caps[0])\n",
    "    new_keys = [key for key in old_dataset.keys() if len(old_dataset[key][0])==5 and len(old_dataset[key][1])==5] # choose only the 5-lengthy stories\n",
    "    input_captions = [[caps[choose_cap] for caps in image_caps] for image_caps in source_inputs if len(image_caps)==5] \n",
    "    target_stories = [' '.join(sent_targets[i]) for i in range(len(sent_targets)) if len(sent_targets[i])==5]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"The number of new keys are:\", len(new_keys))\n",
    "        print(\"Number of captions: \", len(input_captions))\n",
    "        print(\"Number of stories: \", len(target_stories))\n",
    "\n",
    "    assert len(new_keys) == len(input_captions) == len(target_stories), \\\n",
    "    f\"AssertionError: The lengths are not the same! new_keys: {len(new_keys)}, input_captions: {len(input_captions)}, target_stories: {len(target_stories)}\"\n",
    "    print(\"All lengths are equal.\")\n",
    "\n",
    "    new_dataset = {}\n",
    "    for j,key in enumerate(new_keys):\n",
    "        new_dataset[key] = (input_captions[j],target_stories[j])\n",
    "\n",
    "    new_dataset['junk'] = (\"junk1\",\"junk2\") \n",
    "    return new_dataset\n",
    "\n",
    "new_train_dataset1 = combine_sent_stories(train_dataset, 0)\n",
    "new_val_dataset1 = combine_sent_stories(val_dataset, 0)\n",
    "new_test_dataset1 = combine_sent_stories(test_dataset, 0)\n",
    "# print(\"----------------------------------------------------\")\n",
    "# print(\"The length of the new Train Dataset is:\", len(new_train_dataset))\n",
    "# print(\"The length of the new Validation Dataset is:\", len(new_val_dataset))\n",
    "# print(\"The length of the new Test Dataset is:\", len(new_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731a2ebd-e5c7-4957-be40-9cbaad90609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lengths are equal.\n",
      "All lengths are equal.\n",
      "All lengths are equal.\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset2 = combine_sent_stories(train_dataset, 1)\n",
    "new_val_dataset2 = combine_sent_stories(val_dataset, 1)\n",
    "new_test_dataset2 = combine_sent_stories(test_dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf59dad7-ab0c-48a8-ac95-a2a8de3fd70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lengths are equal.\n",
      "All lengths are equal.\n",
      "All lengths are equal.\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset3 = combine_sent_stories(train_dataset, 2)\n",
    "new_val_dataset3 = combine_sent_stories(val_dataset, 2)\n",
    "new_test_dataset3 = combine_sent_stories(test_dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4255c76-5dd4-46c1-b1c6-d6250c5cf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path1 = '/data/admitosstorage/Phase_2/data_phase2/new_train_dataset1.json'\n",
    "val_path1 = '/data/admitosstorage/Phase_2/data_phase2/new_val_dataset1.json'\n",
    "test_path1 = '/data/admitosstorage/Phase_2/data_phase2/new_test_dataset1.json'\n",
    "\n",
    "with open(train_path1, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_train_dataset1, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(val_path1, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_val_dataset1, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(test_path1, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(new_test_dataset1, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34a77a61-d078-450d-aa9e-76e5d6785856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26571\n",
      "3320\n",
      "3339\n"
     ]
    }
   ],
   "source": [
    "print(len(new_train_dataset1))\n",
    "print(len(new_val_dataset1))\n",
    "print(len(new_test_dataset1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ffdca-999d-4563-8ba9-16d3d2e0d365",
   "metadata": {},
   "source": [
    "### Find the vocabulary across the datasets (train,val,test), following both ways (admitos, yingjin) \n",
    "\n",
    "### DONT RUN THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c98962-146f-4d80-beee-85a25939cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation(sentences):\n",
    "    modified_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Use regex to find punctuation marks and separate them from preceding words\n",
    "        modified_sentence = re.sub(r'([.,!?;:])', r' \\1', sentence)\n",
    "        modified_sentences.append(modified_sentence)\n",
    "    return modified_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd78873-2a8b-47d2-904f-2bc333027892",
   "metadata": {},
   "source": [
    "### Admitos Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b110689-5e2a-47ce-b08c-5cbdaa5a75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with the training dataset: ...\n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "Continuing with the validation dataset: ...\n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "Ending with the test dataset: \n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "All train tokens in INPUT:  4745731\n",
      "All unique train tokens in INPUT:  29330\n",
      "All train tokens in TARGET:  1504421\n",
      "All unique train tokens in TARGET:  30981\n",
      "------------------------------------------------------------------------------------\n",
      "All validation tokens in INPUT:  589986\n",
      "All unique validation tokens in INPUT:  10067\n",
      "All validation tokens in TARGET:  190118\n",
      "All unique validation tokens in TARGET:  10836\n",
      "------------------------------------------------------------------------------------\n",
      "All test tokens in INPUT:  595651\n",
      "All unique test tokens in INPUT:  10260\n",
      "All test tokens in TARGET:  187222\n",
      "All unique test tokens in TARGET:  11382\n"
     ]
    }
   ],
   "source": [
    "def find_vocabulary_admitos(a_dataset):\n",
    "    inputs = [value[0] for key,value in a_dataset.items()]\n",
    "    targets = [value[1] for key,value in a_dataset.items()]\n",
    "    all_tokens_input = []\n",
    "    all_tokens_target = []\n",
    "    for inp in inputs:\n",
    "        all_caps_tokens = [] # all tokens appeared in the caps of an image\n",
    "        for caps in inp:\n",
    "            mod_caps = separate_punctuation(caps)\n",
    "            split_caps = mod_caps[0].split() + mod_caps[1].split() + mod_caps[2].split()\n",
    "            all_caps_tokens = all_caps_tokens + split_caps\n",
    "        all_tokens_input = all_tokens_input + all_caps_tokens\n",
    "        \n",
    "    print(\"##### FINISHED WITH THE INPUTS VOCABULARY #####\")\n",
    "    for tgt in targets:\n",
    "        story_tokens = [] # all tokens appeared in the story sentences of an image\n",
    "        mod_tgt = separate_punctuation(tgt)\n",
    "        for sent in mod_tgt:\n",
    "            story_tokens = story_tokens + sent.split()\n",
    "        all_tokens_target = all_tokens_target + story_tokens\n",
    "\n",
    "    \n",
    "    print(\"##### FINISHED WITH THE TARGETS VOCABULARY #####\")\n",
    "    print(\"------------------------   FINISH FUNCTION   ----------------------------\")\n",
    "    return all_tokens_input, all_tokens_target\n",
    "\n",
    "print(f\"Starting with the training dataset: ...\")\n",
    "all_train_tokens_input, all_train_tokens_target = find_vocabulary_admitos(train_dataset)\n",
    "print(f\"Continuing with the validation dataset: ...\")\n",
    "all_val_tokens_input, all_val_tokens_target = find_vocabulary_admitos(val_dataset)\n",
    "print(f\"Ending with the test dataset: \")\n",
    "all_test_tokens_input, all_test_tokens_target = find_vocabulary_admitos(test_dataset)\n",
    "\n",
    "print(\"All train tokens in INPUT: \", len(all_train_tokens_input))\n",
    "print(\"All unique train tokens in INPUT: \", len(list(set(all_train_tokens_input))))\n",
    "print(\"All train tokens in TARGET: \", len(all_train_tokens_target))\n",
    "print(\"All unique train tokens in TARGET: \", len(list(set(all_train_tokens_target))))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"All validation tokens in INPUT: \", len(all_val_tokens_input))\n",
    "print(\"All unique validation tokens in INPUT: \", len(list(set(all_val_tokens_input))))\n",
    "print(\"All validation tokens in TARGET: \", len(all_val_tokens_target))\n",
    "print(\"All unique validation tokens in TARGET: \", len(list(set(all_val_tokens_target))))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"All test tokens in INPUT: \", len(all_test_tokens_input))\n",
    "print(\"All unique test tokens in INPUT: \", len(list(set(all_test_tokens_input))))\n",
    "print(\"All test tokens in TARGET: \", len(all_test_tokens_target))\n",
    "print(\"All unique test tokens in TARGET: \", len(list(set(all_test_tokens_target))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02805894-6ce6-440f-b90e-da98e4e8965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the unique tokens apearred in VIST DII dataset:  32723\n",
      "------------------------------------------------------------------\n",
      "All the unique tokens apearred in VIST SIS dataset:  34582\n"
     ]
    }
   ],
   "source": [
    "unique_train_tokens_input = list(set(all_train_tokens_input))\n",
    "unique_val_tokens_input = list(set(all_val_tokens_input))\n",
    "unique_test_tokens_input = list(set(all_test_tokens_input))\n",
    "all_unique_tokens_input = list(set(unique_train_tokens_input + unique_val_tokens_input + unique_test_tokens_input))\n",
    "print(\"All the unique tokens apearred in VIST DII dataset: \", len(all_unique_tokens_input))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "unique_train_tokens_target = list(set(all_train_tokens_target))\n",
    "unique_val_tokens_target = list(set(all_val_tokens_target))\n",
    "unique_test_tokens_target = list(set(all_test_tokens_target))\n",
    "all_unique_tokens_target = list(set(unique_train_tokens_target + unique_val_tokens_target + unique_test_tokens_target))\n",
    "print(\"All the unique tokens apearred in VIST SIS dataset: \", len(all_unique_tokens_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb60d54-90ad-4f3a-ba3d-3ee78e78a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Admitos Vocabularies\n",
    "vocab_admitos_train_captions = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/train_vocab_captions_admitos.pkl'\n",
    "vocab_admitos_train_stories = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/train_vocab_stories_admitos.pkl'\n",
    "\n",
    "with open(vocab_admitos_train_captions, 'wb') as f:\n",
    "    pickle.dump(unique_train_tokens_input, f)\n",
    "\n",
    "with open(vocab_admitos_train_stories, 'wb') as f:\n",
    "    pickle.dump(unique_train_tokens_target, f)\n",
    "\n",
    "vocab_admitos_val_captions = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/val_vocab_captions_admitos.pkl'\n",
    "vocab_admitos_val_stories = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/val_vocab_stories_admitos.pkl'\n",
    "\n",
    "with open(vocab_admitos_val_captions, 'wb') as f:\n",
    "    pickle.dump(unique_val_tokens_input, f)\n",
    "\n",
    "with open(vocab_admitos_val_stories, 'wb') as f:\n",
    "    pickle.dump(unique_val_tokens_target, f)\n",
    "    \n",
    "vocab_admitos_test_captions = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/test_vocab_captions_admitos.pkl'\n",
    "vocab_admitos_test_stories = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/test_vocab_stories_admitos.pkl'\n",
    "\n",
    "with open(vocab_admitos_test_captions, 'wb') as f:\n",
    "    pickle.dump(unique_test_tokens_input, f)\n",
    "\n",
    "with open(vocab_admitos_test_stories, 'wb') as f:\n",
    "    pickle.dump(unique_test_tokens_target, f)\n",
    "\n",
    "vocab_admitos_all_captions = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/all_vocab_captions_admitos.pkl'\n",
    "vocab_admitos_all_stories = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/Vocabs/all_vocab_stories_admitos.pkl'\n",
    "\n",
    "with open(vocab_admitos_all_captions, 'wb') as f:\n",
    "    pickle.dump(all_unique_tokens_input, f)\n",
    "\n",
    "with open(vocab_admitos_all_stories, 'wb') as f:\n",
    "    pickle.dump(all_unique_tokens_target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86757ece-7671-4609-96ca-930949442b03",
   "metadata": {},
   "source": [
    "### Yingjin Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9287166c-e98d-4364-9ca7-b97296ad36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with the training dataset: ...\n",
      "We skip the input -->  junk1\n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "We skip the target -->  junk2\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "Continuing with the validation dataset: ...\n",
      "We skip the input -->  junk1\n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "We skip the target -->  junk2\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "Ending with the test dataset: \n",
      "We skip the input -->  junk1\n",
      "##### FINISHED WITH THE INPUTS VOCABULARY #####\n",
      "We skip the target -->  junk2\n",
      "##### FINISHED WITH THE TARGETS VOCABULARY #####\n",
      "------------------------   FINISH FUNCTION   ----------------------------\n",
      "\n",
      "All train tokens in INPUT:  1577095\n",
      "All unique train tokens in INPUT:  17376\n",
      "All train tokens in TARGET:  1499284\n",
      "All unique train tokens in TARGET:  30924\n",
      "------------------------------------------------------------------------------------\n",
      "All validation tokens in INPUT:  196150\n",
      "All unique validation tokens in INPUT:  5797\n",
      "All validation tokens in TARGET:  189793\n",
      "All unique validation tokens in TARGET:  10829\n",
      "------------------------------------------------------------------------------------\n",
      "All test tokens in INPUT:  198126\n",
      "All unique test tokens in INPUT:  5867\n",
      "All test tokens in TARGET:  187029\n",
      "All unique test tokens in TARGET:  11378\n"
     ]
    }
   ],
   "source": [
    "def find_vocabulary_yingjin(a_dataset):\n",
    "    inputs = [value[0] for value in a_dataset.values()]\n",
    "    targets = [value[1] for value in a_dataset.values()]\n",
    "    all_tokens_input = []\n",
    "    all_tokens_target = []\n",
    "    for j,inp in enumerate(inputs):\n",
    "        if j==len(inputs)-1:\n",
    "            print(\"We skip the input --> \", inp)\n",
    "            continue\n",
    "        all_caps_tokens = [] # all tokens appeared in the caps of an image\n",
    "        mod_inp = separate_punctuation(inp)\n",
    "        for cap in mod_inp:\n",
    "            all_caps_tokens = all_caps_tokens + cap.split()\n",
    "        all_tokens_input = all_tokens_input + all_caps_tokens\n",
    "    print(\"##### FINISHED WITH THE INPUTS VOCABULARY #####\")\n",
    "    all_story_tokens = [] # all tokens appeared in the story sentences of an image\n",
    "    targets_mod = separate_punctuation(targets)\n",
    "    for j,tgt in enumerate(targets_mod):\n",
    "        if j==len(targets)-1:\n",
    "            print(\"We skip the target --> \", tgt)\n",
    "            continue\n",
    "        all_story_tokens = all_story_tokens + tgt.split()\n",
    "    \n",
    "    print(\"##### FINISHED WITH THE TARGETS VOCABULARY #####\")\n",
    "    print(\"------------------------   FINISH FUNCTION   ----------------------------\")\n",
    "    return all_tokens_input, all_story_tokens\n",
    "\n",
    "print(f\"Starting with the training dataset: ...\")\n",
    "all_train_tokens_input, all_train_tokens_target = find_vocabulary_yingjin(new_train_dataset)\n",
    "print(f\"Continuing with the validation dataset: ...\")\n",
    "all_val_tokens_input, all_val_tokens_target = find_vocabulary_yingjin(new_val_dataset)\n",
    "print(f\"Ending with the test dataset: \")\n",
    "all_test_tokens_input, all_test_tokens_target = find_vocabulary_yingjin(new_test_dataset)\n",
    "\n",
    "print()\n",
    "print(\"All train tokens in INPUT: \", len(all_train_tokens_input))\n",
    "print(\"All unique train tokens in INPUT: \", len(list(set(all_train_tokens_input))))\n",
    "print(\"All train tokens in TARGET: \", len(all_train_tokens_target))\n",
    "print(\"All unique train tokens in TARGET: \", len(list(set(all_train_tokens_target))))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"All validation tokens in INPUT: \", len(all_val_tokens_input))\n",
    "print(\"All unique validation tokens in INPUT: \", len(list(set(all_val_tokens_input))))\n",
    "print(\"All validation tokens in TARGET: \", len(all_val_tokens_target))\n",
    "print(\"All unique validation tokens in TARGET: \", len(list(set(all_val_tokens_target))))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"All test tokens in INPUT: \", len(all_test_tokens_input))\n",
    "print(\"All unique test tokens in INPUT: \", len(list(set(all_test_tokens_input))))\n",
    "print(\"All test tokens in TARGET: \", len(all_test_tokens_target))\n",
    "print(\"All unique test tokens in TARGET: \", len(list(set(all_test_tokens_target))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5b10b94-2724-4795-a1ba-6095a639c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the unique tokens apearred in VIST DII dataset:  19423\n",
      "------------------------------------------------------------------\n",
      "All the unique tokens apearred in VIST SIS dataset:  34519\n"
     ]
    }
   ],
   "source": [
    "unique_train_tokens_input = list(set(all_train_tokens_input))\n",
    "unique_val_tokens_input = list(set(all_val_tokens_input))\n",
    "unique_test_tokens_input = list(set(all_test_tokens_input))\n",
    "all_unique_tokens_input = list(set(unique_train_tokens_input + unique_val_tokens_input + unique_test_tokens_input))\n",
    "print(\"All the unique tokens apearred in VIST DII dataset: \", len(all_unique_tokens_input))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "unique_train_tokens_target = list(set(all_train_tokens_target))\n",
    "unique_val_tokens_target = list(set(all_val_tokens_target))\n",
    "unique_test_tokens_target = list(set(all_test_tokens_target))\n",
    "all_unique_tokens_target = list(set(unique_train_tokens_target + unique_val_tokens_target + unique_test_tokens_target))\n",
    "print(\"All the unique tokens apearred in VIST SIS dataset: \", len(all_unique_tokens_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17232fb9-2c1f-4a5f-8bc8-9f3d04b5497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Yingjin Vocabularies\n",
    "vocab_yingjin_train_captions = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/train_vocab_captions_yingjin.pkl'\n",
    "vocab_yingjin_train_stories = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/train_vocab_stories_yingjin.pkl'\n",
    "\n",
    "with open(vocab_yingjin_train_captions, 'wb') as f:\n",
    "    pickle.dump(unique_train_tokens_input, f)\n",
    "\n",
    "with open(vocab_yingjin_train_stories, 'wb') as f:\n",
    "    pickle.dump(unique_train_tokens_target, f)\n",
    "\n",
    "vocab_yingjin_val_captions = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/val_vocab_captions_yingjin.pkl'\n",
    "vocab_yingjin_val_stories = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/val_vocab_stories_yingjin.pkl'\n",
    "\n",
    "with open(vocab_yingjin_val_captions, 'wb') as f:\n",
    "    pickle.dump(unique_val_tokens_input, f)\n",
    "\n",
    "with open(vocab_yingjin_val_stories, 'wb') as f:\n",
    "    pickle.dump(unique_val_tokens_target, f)\n",
    "    \n",
    "vocab_yingjin_test_captions = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/test_vocab_captions_yingjin.pkl'\n",
    "vocab_yingjin_test_stories = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/test_vocab_stories_yingjin.pkl'\n",
    "\n",
    "with open(vocab_yingjin_test_captions, 'wb') as f:\n",
    "    pickle.dump(unique_test_tokens_input, f)\n",
    "\n",
    "with open(vocab_yingjin_test_stories, 'wb') as f:\n",
    "    pickle.dump(unique_test_tokens_target, f)\n",
    "\n",
    "vocab_yingjin_all_captions = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/all_vocab_captions_yingjin.pkl'\n",
    "vocab_yingjin_all_stories = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/Vocabs/all_vocab_stories_yingjin.pkl'\n",
    "\n",
    "with open(vocab_yingjin_all_captions, 'wb') as f:\n",
    "    pickle.dump(all_unique_tokens_input, f)\n",
    "\n",
    "with open(vocab_yingjin_all_stories, 'wb') as f:\n",
    "    pickle.dump(all_unique_tokens_target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa91976-023e-4b49-bc49-8a2380ef416a",
   "metadata": {},
   "source": [
    "### TILL HERE\n",
    "\n",
    "### (RUN FROM HERE)\n",
    "\n",
    "## Preprocess and use of our own Tokenizer to tokenize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a083466-aff2-44b0-9f34-6c9ff3ee739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from t4 import T4tokenizer\n",
    "import itertools\n",
    "\n",
    "def load_vocabs(mystr):\n",
    "    if mystr=='admitos' or mystr=='yingjin':\n",
    "        vocab_train_captions = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/train_vocab_captions_{mystr}.pkl'\n",
    "        vocab_train_stories = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/train_vocab_stories_{mystr}.pkl'\n",
    "    \n",
    "        with open(vocab_train_captions, 'rb') as f:\n",
    "            vocab_train_caps = pickle.load(f)\n",
    "    \n",
    "        with open(vocab_train_stories, 'rb') as f:\n",
    "            vocab_train_strs = pickle.load(f)\n",
    "    \n",
    "        vocab_val_captions = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/val_vocab_captions_{mystr}.pkl'\n",
    "        vocab_val_stories = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/val_vocab_stories_{mystr}.pkl'\n",
    "    \n",
    "        with open(vocab_val_captions, 'rb') as f:\n",
    "            vocab_val_caps = pickle.load(f)\n",
    "    \n",
    "        with open(vocab_val_stories, 'rb') as f:\n",
    "            vocab_val_strs = pickle.load(f)\n",
    "    \n",
    "        vocab_test_captions = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/test_vocab_captions_{mystr}.pkl'\n",
    "        vocab_test_stories = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/test_vocab_stories_{mystr}.pkl'\n",
    "        \n",
    "        with open(vocab_test_captions, 'rb') as f:\n",
    "            vocab_test_caps = pickle.load(f)\n",
    "    \n",
    "        with open(vocab_test_stories, 'rb') as f:\n",
    "            vocab_test_strs = pickle.load(f)\n",
    "    \n",
    "        vocab_all_captions = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/all_vocab_captions_{mystr}.pkl'\n",
    "        vocab_all_stories = f'/data/admitosstorage/Phase_2/data_phase2/{mystr.capitalize()}_way/Vocabs/all_vocab_stories_{mystr}.pkl'\n",
    "    \n",
    "        with open(vocab_all_captions, 'rb') as f:\n",
    "            all_vocab_captions = pickle.load(f)\n",
    "    \n",
    "        with open(vocab_all_stories, 'rb') as f:\n",
    "            all_vocab_stories = pickle.load(f)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported Vocabulary folder\")\n",
    "\n",
    "    return vocab_train_caps, vocab_train_strs, vocab_val_caps, vocab_val_strs,\\\n",
    "            vocab_test_caps, vocab_test_strs, all_vocab_captions, all_vocab_stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80e60b5f-b16c-41d1-b03e-6fa3cb28905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the unique tokens appeared in VIST dataset:  40804\n"
     ]
    }
   ],
   "source": [
    "#name = 'admitos'\n",
    "name = 'yingjin'\n",
    "train_vocab_caps, train_vocab_strs, val_vocab_caps, val_vocab_strs, test_vocab_caps, test_vocab_strs, \\\n",
    "total_vocab_captions, total_vocab_stories = load_vocabs(name)\n",
    "\n",
    "all_unique_tokens = list(set(total_vocab_captions + total_vocab_stories))\n",
    "print(\"All the unique tokens appeared in VIST dataset: \", len(all_unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16cef5d2-5672-436a-a760-ad36f1ef56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19447\n",
      "34540\n",
      "40823\n"
     ]
    }
   ],
   "source": [
    "result = string.punctuation \n",
    "punctuation_tokens = [elm for elm in result]\n",
    "special_tokens = ['[PAD]', '[CLS]', '[SEP]', '[UNK]']\n",
    "dii_vocab = total_vocab_captions + punctuation_tokens\n",
    "sis_vocab = total_vocab_stories + punctuation_tokens\n",
    "total_vocab = all_unique_tokens + punctuation_tokens\n",
    "dii_vocab = list(set(dii_vocab))\n",
    "sis_vocab = list(set(sis_vocab))\n",
    "total_vocab = list(set(total_vocab))\n",
    "dii_vocab = special_tokens + dii_vocab\n",
    "sis_vocab = special_tokens + sis_vocab\n",
    "total_vocab = special_tokens + total_vocab\n",
    "print(len(dii_vocab))\n",
    "print(len(sis_vocab))\n",
    "print(len(total_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "002da019-33cc-4fc5-8ea5-2dfcd7734eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_admitos_total_dii_vocab = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/Vocabs/{name}_dii_vocab.pkl'\n",
    "vocab_admitos_total_sis_vocab = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/Vocabs/{name}_sis_vocab.pkl'\n",
    "vocab_admitos_combined = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/Vocabs/all_{name}_vocab.pkl'\n",
    "\n",
    "with open(vocab_admitos_total_dii_vocab, 'wb') as f:\n",
    "    pickle.dump(dii_vocab, f)\n",
    "\n",
    "with open(vocab_admitos_total_sis_vocab, 'wb') as f:\n",
    "    pickle.dump(sis_vocab, f)\n",
    "\n",
    "with open(vocab_admitos_combined, 'wb') as f:\n",
    "    pickle.dump(total_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33301ad5-82a4-49f7-a983-3538d2d80f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_non5_entries(dataset, name):\n",
    "    keys_to_delete = []\n",
    "    for key, value in dataset.items():\n",
    "        if key == 'title':\n",
    "            continue\n",
    "        if len(value[0]) < 5:\n",
    "            keys_to_delete.append(key)\n",
    "    # Delete the keys after iteration is complete\n",
    "    print(f\"The keys that are about to delete in {name} set, are: {len(keys_to_delete)}\")\n",
    "    for key in keys_to_delete:\n",
    "        dataset.pop(key)\n",
    "    return dataset\n",
    "\n",
    "def extract_caps_stories(a_dataset, strategy):\n",
    "    train_captions = [value[0] for value in a_dataset[0].values()]\n",
    "    if strategy == 'yingjin':\n",
    "        train_captions = train_captions[:-1]\n",
    "    train_stories = [value[1] for value in a_dataset[0].values()]\n",
    "    if strategy == 'yingjin':\n",
    "        train_stories = train_stories[:-1]\n",
    "    \n",
    "    val_captions = [value[0] for value in a_dataset[1].values()]\n",
    "    if strategy == 'yingjin':    \n",
    "        val_captions = val_captions[:-1]\n",
    "    val_stories = [value[1] for value in a_dataset[1].values()]\n",
    "    if strategy == 'yingjin':\n",
    "        val_stories = val_stories[:-1]\n",
    "    \n",
    "    test_captions = [value[0] for value in a_dataset[2].values()]\n",
    "    if strategy == 'yingjin':\n",
    "        test_captions = test_captions[:-1]\n",
    "    test_stories = [value[1] for value in a_dataset[2].values()]\n",
    "    if strategy == 'yingjin': \n",
    "        test_stories = test_stories[:-1]\n",
    "\n",
    "    return train_captions, train_stories, val_captions, val_stories, test_captions, test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5406d58c-c423-4f39-8cc6-0b380ed1090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if name == 'admitos':\n",
    "    refined_train_dataset = delete_non5_entries(train_dataset, \"TRAIN\")\n",
    "    refined_val_dataset = delete_non5_entries(val_dataset, \"VALIDATION\")\n",
    "    refined_test_dataset = delete_non5_entries(test_dataset, \"TEST\")\n",
    "    train_captions, train_stories, val_captions, val_stories, test_captions, test_stories = extract_caps_stories([refined_train_dataset, refined_val_dataset, refined_test_dataset],name)\n",
    "elif name == 'yingjin':\n",
    "    train_captions1, train_stories1, val_captions1, val_stories1, test_captions1, test_stories1 = extract_caps_stories([new_train_dataset1, new_val_dataset1, new_test_dataset1], name)\n",
    "    train_captions2, train_stories2, val_captions2, val_stories2, test_captions2, test_stories2 = extract_caps_stories([new_train_dataset2, new_val_dataset2, new_test_dataset2], name)\n",
    "    train_captions3, train_stories3, val_captions3, val_stories3, test_captions3, test_stories3 = extract_caps_stories([new_train_dataset3, new_val_dataset3, new_test_dataset3], name)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported Vocabulary folder\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b17625b-8e28-43bc-a3e5-eacb35621f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    inputs = []\n",
    "    for captions_set in data:\n",
    "        input_text = ' [SEP] '.join(captions_set)\n",
    "        inputs.append(input_text)\n",
    "    return inputs\n",
    "    \n",
    "combined = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5da8fc0d-3122-4059-9292-223c2661d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions1 = prepare_data(train_captions1)\n",
    "val_captions1 = prepare_data(val_captions1)\n",
    "test_captions1 = prepare_data(test_captions1)\n",
    "\n",
    "train_captions2 = prepare_data(train_captions2)\n",
    "val_captions2 = prepare_data(val_captions2)\n",
    "test_captions2 = prepare_data(test_captions2)\n",
    "\n",
    "train_captions3 = prepare_data(train_captions3)\n",
    "val_captions3 = prepare_data(val_captions3)\n",
    "test_captions3 = prepare_data(test_captions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8400bed4-91b1-4d0c-b105-ffbdcdf6f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4_tokenizer = T4tokenizer(total_vocab)\n",
    "\n",
    "if name == 'admitos':\n",
    "    temp_train_captions = [[t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps]) for caps in story_caps] for story_caps in train_captions]\n",
    "    train_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch(list(itertools.chain.from_iterable(sentences)))).view(5,3,-1) for sentences in temp_train_captions]\n",
    "    train_stories_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(sent) for sent in story])) for story in train_stories]\n",
    "\n",
    "    temp_val_captions = [[t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps]) for caps in story_caps] for story_caps in val_captions]\n",
    "    val_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch(list(itertools.chain.from_iterable(sentences)))).view(5,3,-1) for sentences in temp_val_captions]\n",
    "    val_stories_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(sent) for sent in story])) for story in val_stories]\n",
    "\n",
    "    temp_test_captions = [[t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps]) for caps in story_caps] for story_caps in test_captions]\n",
    "    test_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch(list(itertools.chain.from_iterable(sentences)))).view(5,3,-1) for sentences in temp_test_captions]\n",
    "    test_stories_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(sent) for sent in story])) for story in test_stories]\n",
    "\n",
    "elif name == 'yingjin' and not combined:\n",
    "    train_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps])) for caps in train_captions1]\n",
    "    train_stories_tokenized = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in train_stories1]\n",
    "    \n",
    "    val_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps])) for caps in val_captions1]\n",
    "    val_stories_tokenized = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in val_stories1]\n",
    "    \n",
    "    test_captions_tokenized = [torch.tensor(t4_tokenizer.pad_batch([t4_tokenizer.encode(cap) for cap in caps])) for caps in test_captions1]\n",
    "    test_stories_tokenized = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in test_stories1]\n",
    "\n",
    "elif name == 'yingjin' and combined:\n",
    "    train_captions_tokenized1 = [torch.tensor(t4_tokenizer.encode(caption_set)).unsqueeze(0) for caption_set in train_captions1]\n",
    "    train_stories_tokenized1 = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in train_stories1]\n",
    "    \n",
    "    val_captions_tokenized1 = [torch.tensor(t4_tokenizer.encode(caption_set)).unsqueeze(0) for caption_set in val_captions1]\n",
    "    val_stories_tokenized1 = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in val_stories1]\n",
    "    \n",
    "    test_captions_tokenized1 = [torch.tensor(t4_tokenizer.encode(caption_set)).unsqueeze(0) for caption_set in test_captions1]\n",
    "    test_stories_tokenized1 = [torch.tensor(t4_tokenizer.encode(story)).unsqueeze(0) for story in test_stories1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d990c6b-c73c-4d4f-8dc0-a5c3b5b2242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path_train_a = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/train_caps_t4tok.pkl'\n",
    "phase2_path_train_b = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/train_stories_t4tok.pkl'\n",
    "\n",
    "with open(phase2_path_train_a, 'wb') as f:\n",
    "    pickle.dump(train_captions_tokenized, f)\n",
    "\n",
    "with open(phase2_path_train_b, 'wb') as f:\n",
    "    pickle.dump(train_stories_tokenized, f)\n",
    "\n",
    "phase2_path_val_a = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/val_caps_t4tok.pkl'\n",
    "phase2_path_val_b = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/val_stories_t4tok.pkl'\n",
    "\n",
    "with open(phase2_path_val_a, 'wb') as f:\n",
    "    pickle.dump(val_captions_tokenized, f)\n",
    "\n",
    "with open(phase2_path_val_b, 'wb') as f:\n",
    "    pickle.dump(val_stories_tokenized, f)\n",
    "\n",
    "phase2_path_test_a = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/test_caps_t4tok.pkl'\n",
    "phase2_path_test_b = f'/data/admitosstorage/Phase_2/data_phase2/{name.capitalize()}_way/test_stories_t4tok.pkl'\n",
    "\n",
    "with open(phase2_path_test_a, 'wb') as f:\n",
    "    pickle.dump(test_captions_tokenized, f)\n",
    "\n",
    "with open(phase2_path_test_b, 'wb') as f:\n",
    "    pickle.dump(test_stories_tokenized, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1e911ee1-c10c-4466-8837-6e1813e0e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path_train_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_train_caps.pkl'\n",
    "phase2_path_train_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_train_stories.pkl'\n",
    "\n",
    "with open(phase2_path_train_a, 'wb') as f:\n",
    "    pickle.dump(train_captions_tokenized1, f)\n",
    "\n",
    "with open(phase2_path_train_b, 'wb') as f:\n",
    "    pickle.dump(train_stories_tokenized1, f)\n",
    "\n",
    "phase2_path_val_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_val_caps.pkl'\n",
    "phase2_path_val_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_val_stories.pkl'\n",
    "\n",
    "with open(phase2_path_val_a, 'wb') as f:\n",
    "    pickle.dump(val_captions_tokenized1, f)\n",
    "\n",
    "with open(phase2_path_val_b, 'wb') as f:\n",
    "    pickle.dump(val_stories_tokenized1, f)\n",
    "\n",
    "phase2_path_test_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_test_caps.pkl'\n",
    "phase2_path_test_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/t4tok_test_stories.pkl'\n",
    "\n",
    "with open(phase2_path_test_a, 'wb') as f:\n",
    "    pickle.dump(test_captions_tokenized1, f)\n",
    "\n",
    "with open(phase2_path_test_b, 'wb') as f:\n",
    "    pickle.dump(test_stories_tokenized1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf99ef3-cbc5-4169-962b-df6b5ac9c728",
   "metadata": {},
   "source": [
    "## Preprocessing of data and Tokenization with BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0fde1a-c7c2-45db-9bd5-5feac561d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apassadaki/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0b045c-bf0d-4a45-857b-ce55c316edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def tokenization(my_dataset, synthetic_caps=True):\n",
    "    my_tokenized_data = {}\n",
    "    # The text is in the form of (captions,references) \n",
    "    for key, text in list(my_dataset.items())[:-1]:\n",
    "        captions = text[0]\n",
    "        references = text[1]\n",
    "        if synthetic_caps:\n",
    "            tokenized_captions = [tokenizer(sub_captions, padding=True, truncation=True, return_tensors='pt') for sub_captions in captions]\n",
    "        else: \n",
    "            tokenized_captions = tokenizer(captions, padding=True, truncation=True, return_tensors='pt')\n",
    "        tokenized_references = tokenizer(references, padding=True, truncation=True, return_tensors='pt')\n",
    "        my_tokenized_data[key] = (tokenized_captions, tokenized_references)\n",
    "\n",
    "    return my_tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1ac4d-0b98-4e00-bfd6-2d726430ab22",
   "metadata": {},
   "source": [
    "### --> WAY 1: ADMITOS WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63778774-f8dd-4094-826a-c882a8036700",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = tokenization(train_dataset) \n",
    "tokenized_val_data = tokenization(val_dataset)\n",
    "tokenized_test_data = tokenization(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384bef89-bbb4-42cf-b672-ac0e95c5e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path_train = '/data/admitosstorage/Phase_2/data_phase2/tokenized_train_dataset.json'\n",
    "phase2_path_val = '/data/admitosstorage/Phase_2/data_phase2/tokenized_val_dataset.json'\n",
    "phase2_path_test = '/data/admitosstorage/Phase_2/data_phase2/tokenized_test_dataset.json'\n",
    "\n",
    "with open(phase2_path_train, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_data, f)\n",
    "\n",
    "with open(phase2_path_val, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_data, f)\n",
    "\n",
    "with open(phase2_path_test, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c013a47-2339-4daf-8266-7ac61cf836c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709\n",
      "3332\n",
      "3348\n"
     ]
    }
   ],
   "source": [
    "with open(phase2_path_train, 'rb') as f:\n",
    "    tokenized_train_data = pickle.load(f)\n",
    "\n",
    "with open(phase2_path_val, 'rb') as f:\n",
    "    tokenized_val_data = pickle.load(f)\n",
    "\n",
    "with open(phase2_path_test, 'rb') as f:\n",
    "    tokenized_test_data = pickle.load(f)\n",
    "\n",
    "print(len(tokenized_train_data))\n",
    "print(len(tokenized_val_data))\n",
    "print(len(tokenized_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "476a6e25-ea8b-44ec-abcb-4696472b217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Captions:\n",
      "torch.Size([3, 19])\n",
      "torch.Size([3, 13])\n",
      "torch.Size([3, 15])\n",
      "torch.Size([3, 19])\n",
      "torch.Size([3, 17])\n",
      "\n",
      "Tokenized References:\n",
      "torch.Size([5, 13])\n"
     ]
    }
   ],
   "source": [
    "sample_key = '47142'\n",
    "#sample_key = '49042'\n",
    "print(\"Tokenized Captions:\")\n",
    "tok_caps = tokenized_test_data[sample_key][0]\n",
    "for tok_cap in tok_caps:\n",
    "    print(tok_cap['input_ids'].shape)\n",
    "print(\"\\nTokenized References:\")\n",
    "tok_refs = tokenized_test_data[sample_key][1]\n",
    "print(tok_refs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d6c046-f79b-4cdf-b9bc-b0920d2f5c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deletion the entries in the TRAIN dataset were: 26709\n",
      "The keys that are about to delete in TRAIN set, are: 139\n",
      "After deletion the entries in the TRAIN dataset are: 26570\n",
      "\n",
      "Before deletion the entries in the VALIDATION dataset were: 3332\n",
      "The keys that are about to delete in VALIDATION set, are: 13\n",
      "After deletion the entries in the VALIDATION dataset are: 3319\n",
      "\n",
      "Before deletion the entries in the TEST dataset were: 3348\n",
      "The keys that are about to delete in TEST set, are: 10\n",
      "After deletion the entries in the TEST dataset are: 3338\n"
     ]
    }
   ],
   "source": [
    "def delete_non5_entries(tokenized_dataset, name):\n",
    "    keys_to_delete = []\n",
    "    for key, value in tokenized_dataset.items():\n",
    "        if len(value[0]) < 5:\n",
    "            keys_to_delete.append(key)\n",
    "    # Delete the keys after iteration is complete\n",
    "    print(f\"The keys that are about to delete in {name} set, are: {len(keys_to_delete)}\")\n",
    "    for key in keys_to_delete:\n",
    "        tokenized_dataset.pop(key)\n",
    "    return tokenized_dataset\n",
    "\n",
    "print(\"Before deletion the entries in the TRAIN dataset were:\", len(tokenized_train_data))\n",
    "tok_cleaned_train_data = delete_non5_entries(tokenized_train_data.copy(), \"TRAIN\")   \n",
    "print(\"After deletion the entries in the TRAIN dataset are:\", len(tok_cleaned_train_data))\n",
    "print()\n",
    "\n",
    "print(\"Before deletion the entries in the VALIDATION dataset were:\", len(tokenized_val_data))\n",
    "tok_cleaned_val_data = delete_non5_entries(tokenized_val_data.copy(), \"VALIDATION\")   \n",
    "print(\"After deletion the entries in the VALIDATION dataset are:\", len(tok_cleaned_val_data))\n",
    "print()\n",
    "\n",
    "print(\"Before deletion the entries in the TEST dataset were:\", len(tokenized_test_data))\n",
    "tok_cleaned_test_data = delete_non5_entries(tokenized_test_data.copy(), \"TEST\")   \n",
    "print(\"After deletion the entries in the TEST dataset are:\", len(tok_cleaned_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fd0d09f-99dd-4f72-b36a-501ba57f83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disentangle(cleaned_data):\n",
    "    all_tokenized_inputs = []\n",
    "    all_tokenized_references = []\n",
    "    for key,item in cleaned_data.items():\n",
    "        all_tokenized_inputs.append(item[0])\n",
    "        all_tokenized_references.append(item[1])\n",
    "\n",
    "    return all_tokenized_inputs, all_tokenized_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e110bc8-222f-4280-8abe-e2ac6d3c3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_inputs, train_tokenized_references = disentangle(tok_cleaned_train_data)\n",
    "val_tokenized_inputs, val_tokenized_references = disentangle(tok_cleaned_val_data)\n",
    "test_tokenized_inputs, test_tokenized_references = disentangle(tok_cleaned_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926ead30-c96f-4ba7-bc80-7399694145ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pad_entry(tokenized_entry):\n",
    "    padded_entry = {}\n",
    "    def my_transpose_pad(list_of_tensors):\n",
    "        transposed_tensors = [tensor.t() for tensor in list_of_tensors]\n",
    "        padded_tensors = pad_sequence(transposed_tensors, batch_first=True, padding_value=0)\n",
    "        padded_tensors = [tensor.t() for tensor in padded_tensors]\n",
    "        return padded_tensors\n",
    "\n",
    "    # ------------------------ Pad the input-ids from the entry data -----------------------------\n",
    "    temp_input_ids = [tokenized_entry[i]['input_ids'] for i in range(5)]\n",
    "    padded_input_ids = my_transpose_pad(temp_input_ids)\n",
    "    padded_entry['input_ids'] = padded_input_ids\n",
    "\n",
    "    # ------------------------ Pad the token-type-ids from the entry data ---------------------------\n",
    "    temp_token_type_ids = [tokenized_entry[i]['token_type_ids'] for i in range(5)]\n",
    "    padded_token_type_ids = my_transpose_pad(temp_token_type_ids)\n",
    "    padded_entry['token_type_ids'] = padded_token_type_ids\n",
    "\n",
    "    # ------------------------ Pad the attention-mask from the entry data ---------------------------\n",
    "    temp_attention_mask = [tokenized_entry[i]['attention_mask'] for i in range(5)]\n",
    "    padded_att_mask = my_transpose_pad(temp_attention_mask)\n",
    "    padded_entry['attention_mask'] = padded_att_mask\n",
    "\n",
    "    return(padded_entry)\n",
    "\n",
    "def pad_entries(tok_inputs):\n",
    "    all_padded_entries = []\n",
    "    for j in range(len(tok_inputs)):\n",
    "        padded_captions = transform_pad_entry(tok_inputs[j])\n",
    "        all_padded_entries.append(padded_captions)\n",
    "    \n",
    "    return all_padded_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc452ba-ccf4-4c4d-a808-496e1b18ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_entries = pad_entries(train_tokenized_inputs)\n",
    "val_padded_entries = pad_entries(val_tokenized_inputs)\n",
    "test_padded_entries = pad_entries(test_tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e6df6b-65ff-4711-8172-a3420ce14572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disentangle_entries(some_entries):\n",
    "    all_input_ids = []\n",
    "    all_token_type_ids = []\n",
    "    all_attention_masks = []\n",
    "    for i in range(len(some_entries)):\n",
    "        all_input_ids.append(some_entries[i][\"input_ids\"])\n",
    "        all_token_type_ids.append(some_entries[i][\"token_type_ids\"])\n",
    "        all_attention_masks.append(some_entries[i][\"attention_mask\"])\n",
    "\n",
    "    return all_input_ids, all_token_type_ids, all_attention_masks\n",
    "\n",
    "def transform_inner(a_big_list):\n",
    "    new_tensor_list = []\n",
    "\n",
    "    for sublist in a_big_list:\n",
    "        stacked_tensor = torch.stack(sublist, dim=0)\n",
    "        new_tensor_list.append(stacked_tensor)\n",
    "    \n",
    "    return new_tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddfe684c-9518-4570-af9d-fc422f112390",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_token_types, train_att_masks = disentangle_entries(train_padded_entries)\n",
    "val_input_ids, val_token_types, val_att_masks = disentangle_entries(val_padded_entries)\n",
    "test_input_ids, test_token_types, test_att_masks = disentangle_entries(test_padded_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fbe2baf-8f3f-4390-9413-3d31bc343e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_input_ids, train_ref_token_types, train_ref_att_masks = disentangle_entries(train_tokenized_references)\n",
    "val_ref_input_ids, val_ref_token_types, val_ref_att_masks = disentangle_entries(val_tokenized_references)\n",
    "test_ref_input_ids, test_ref_token_types, test_ref_att_masks = disentangle_entries(test_tokenized_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04ee9f8e-6d0d-473d-9c49-dd0c8f0ecd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_input_ids = transform_inner(train_input_ids)\n",
    "new_train_token_types = transform_inner(train_token_types)\n",
    "new_train_att_masks = transform_inner(train_att_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6febcf87-dad8-4ab8-8f43-de2e0eacabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_input_ids = transform_inner(val_input_ids)\n",
    "new_val_token_types = transform_inner(val_token_types)\n",
    "new_val_att_masks = transform_inner(val_att_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9aa54e40-b953-4bc8-a846-e2644903d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_input_ids = transform_inner(test_input_ids)\n",
    "new_test_token_types = transform_inner(test_token_types)\n",
    "new_test_att_masks = transform_inner(test_att_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05c30d62-1dc0-4ab0-8589-5ce584799295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Input shape:  torch.Size([5, 3, 21])\n",
      "Targeted Output shape: torch.Size([5, 17])\n"
     ]
    }
   ],
   "source": [
    "print(\"Given Input shape: \", new_train_input_ids[0].shape)\n",
    "print(\"Targeted Output shape:\", train_ref_input_ids[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b968ffe-ff2b-4ca6-9514-cffd0c3d86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path_train_src = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_input_train_data.pkl'\n",
    "phase2_path_train_tgt = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_ref_train_data.pkl'\n",
    "\n",
    "with open(phase2_path_train_src, 'wb') as f:\n",
    "    pickle.dump(new_train_input_ids, f)\n",
    "\n",
    "with open(phase2_path_train_tgt, 'wb') as f:\n",
    "    pickle.dump(train_ref_input_ids, f)\n",
    "\n",
    "\n",
    "phase2_path_val_src = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_input_val_data.pkl'\n",
    "phase2_path_val_tgt = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_ref_val_data.pkl'\n",
    "\n",
    "with open(phase2_path_val_src, 'wb') as f:\n",
    "    pickle.dump(new_val_input_ids, f)\n",
    "\n",
    "with open(phase2_path_val_tgt, 'wb') as f:\n",
    "    pickle.dump(val_ref_input_ids, f)\n",
    "\n",
    "\n",
    "phase2_path_test_src = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_input_test_data.pkl'\n",
    "phase2_path_test_tgt = '/data/admitosstorage/Phase_2/data_phase2/Admitos_way/final_ref_test_data.pkl'\n",
    "\n",
    "with open(phase2_path_test_src, 'wb') as f:\n",
    "    pickle.dump(new_test_input_ids, f)\n",
    "\n",
    "with open(phase2_path_test_tgt, 'wb') as f:\n",
    "    pickle.dump(test_ref_input_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825edd6a-6cb1-44fc-a474-18b453523021",
   "metadata": {},
   "source": [
    "### --> WAY2: YINGJIN WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f674e81b-ccb5-4b2d-99f4-06afaa2ec8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = tokenization(new_train_dataset, False)\n",
    "tokenized_val_data = tokenization(new_val_dataset, False)\n",
    "tokenized_test_data = tokenization(new_test_dataset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3bf38d0-baac-41ca-957f-5a62050f0e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26570\n",
      "3319\n",
      "3338\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_train_data))\n",
    "print(len(tokenized_val_data))\n",
    "print(len(tokenized_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d69eb6a-d13e-4111-9dd4-94c5fde299dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_caps = [tokenized_train_data[key][0]['input_ids'] for key in tokenized_train_data.keys()]\n",
    "tokenized_train_stories = [tokenized_train_data[key][1]['input_ids'] for key in tokenized_train_data.keys()]\n",
    "\n",
    "tokenized_val_caps = [tokenized_val_data[key][0]['input_ids'] for key in tokenized_val_data.keys()]\n",
    "tokenized_val_stories = [tokenized_val_data[key][1]['input_ids'] for key in tokenized_val_data.keys()]\n",
    "\n",
    "tokenized_test_caps = [tokenized_test_data[key][0]['input_ids'] for key in tokenized_test_data.keys()]\n",
    "tokenized_test_stories = [tokenized_test_data[key][1]['input_ids'] for key in tokenized_test_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01c9bd34-9e41-4e6d-89a7-afa61676d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path_yingjin_train_a = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_train_input_caps.pkl'\n",
    "phase2_path_yingjin_train_b = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_train_ref_stories.pkl'\n",
    "\n",
    "with open(phase2_path_yingjin_train_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_caps, f)\n",
    "\n",
    "with open(phase2_path_yingjin_train_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_stories, f)\n",
    "\n",
    "phase2_path_yingjin_val_a = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_val_input_caps.pkl'\n",
    "phase2_path_yingjin_val_b = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_val_ref_stories.pkl'\n",
    "\n",
    "with open(phase2_path_yingjin_val_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_caps, f)\n",
    "\n",
    "with open(phase2_path_yingjin_val_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_stories, f)\n",
    "\n",
    "phase2_path_yingjin_test_a = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_test_input_caps.pkl'\n",
    "phase2_path_yingjin_test_b = '/data/admitosstorage/Phase_2/data_phase2/Yingjin_way/final_test_ref_stories.pkl'\n",
    "\n",
    "with open(phase2_path_yingjin_test_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_caps, f)\n",
    "\n",
    "with open(phase2_path_yingjin_test_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_stories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb314834-4fe4-4243-9611-e61a9a4aa3f5",
   "metadata": {},
   "source": [
    "### --> WAY3: COMBINED WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b95949c-7442-4a24-92a2-5023a74fb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for captions, story in data:\n",
    "        input_text = ' [SEP] '.join(captions)\n",
    "        inputs.append(input_text)\n",
    "        outputs.append(story)\n",
    "    return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76670092-064a-462d-b416-6dce1afea902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_data(new_train_dataset,new_val_dataset,new_test_dataset):\n",
    "    my_train_data = [prepare_data([train_tup]) for train_tup in list(new_train_dataset.values())[:-1]]\n",
    "    my_val_data = [prepare_data([val_tup]) for val_tup in list(new_val_dataset.values())[:-1]]\n",
    "    my_test_data = [prepare_data([test_tup]) for test_tup in list(new_test_dataset.values())[:-1]]\n",
    "    \n",
    "    my_train_caps =  [item[0] for item in my_train_data]\n",
    "    my_train_stories =  [item[1] for item in my_train_data]\n",
    "    \n",
    "    my_val_caps =  [item[0] for item in my_val_data]\n",
    "    my_val_stories =  [item[1] for item in my_val_data]\n",
    "    \n",
    "    my_test_caps =  [item[0] for item in my_test_data]\n",
    "    my_test_stories =  [item[1] for item in my_test_data]\n",
    "    return(my_train_caps, my_train_stories, my_val_caps, my_val_stories, my_test_caps, my_test_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e8a976-6fb4-40c2-ad93-c01cf9a16b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_caps1, train_stories1, val_caps1, val_stories1, test_caps1, test_stories1 = reform_data(new_train_dataset1,new_val_dataset1,new_test_dataset1)\n",
    "train_caps2, train_stories2, val_caps2, val_stories2, test_caps2, test_stories2 = reform_data(new_train_dataset2,new_val_dataset2,new_test_dataset2)\n",
    "train_caps3, train_stories3, val_caps3, val_stories3, test_caps3, test_stories3 = reform_data(new_train_dataset3,new_val_dataset3,new_test_dataset3)\n",
    "\n",
    "if (train_stories1 == train_stories2 == train_stories3) == True:\n",
    "    train_stories = train_stories1\n",
    "    print(\"Done!\")\n",
    "if (val_stories1 == val_stories2 == val_stories3) == True:\n",
    "    val_stories = val_stories1\n",
    "    print(\"Done!\")\n",
    "if (test_stories1 == test_stories2 == test_stories3) == True:\n",
    "    test_stories = test_stories1\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7925492-5f0a-4c8c-a7eb-fde41a42bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize(input_list, tokeinizer):\n",
    "    tokenized_list = [tokenizer(element, padding=True, truncation=True, return_tensors='pt')['input_ids'] for element in input_list]\n",
    "    return tokenized_list\n",
    "\n",
    "# ----------------------------  Tokenize the Captions  ---------------------------------------\n",
    "\n",
    "tokenized_train_captions1 = tokenize(train_caps1, my_tokenizer)\n",
    "tokenized_train_captions2 = tokenize(train_caps2, my_tokenizer)\n",
    "tokenized_train_captions3 = tokenize(train_caps3, my_tokenizer)\n",
    "\n",
    "tokenized_val_captions1 = tokenize(val_caps1, my_tokenizer)\n",
    "tokenized_val_captions2 = tokenize(val_caps2, my_tokenizer)\n",
    "tokenized_val_captions3 = tokenize(val_caps3, my_tokenizer)\n",
    "\n",
    "tokenized_test_captions1 = tokenize(test_caps1, my_tokenizer)\n",
    "tokenized_test_captions2 = tokenize(test_caps2, my_tokenizer)\n",
    "tokenized_test_captions3 = tokenize(test_caps3, my_tokenizer)\n",
    "\n",
    "# ----------------------------  Tokenize the Stories  ---------------------------------------\n",
    "\n",
    "tokenized_train_stories = tokenize(train_stories, my_tokenizer)\n",
    "tokenized_val_stories = tokenize(val_stories, my_tokenizer)\n",
    "tokenized_test_stories = tokenize(test_stories, my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b847a5d2-6863-45c0-a87c-1de929d9a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/train_caps_1.pkl'\n",
    "path_train_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/train_caps_2.pkl'\n",
    "path_train_c = f'/data/admitosstorage/Phase_2/data_phase2/Combined/train_caps_3.pkl'\n",
    "\n",
    "with open(path_train_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_captions1, f)\n",
    "\n",
    "with open(path_train_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_captions2, f)\n",
    "\n",
    "with open(path_train_c, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_captions3, f)\n",
    "\n",
    "path_val_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/val_caps_1.pkl'\n",
    "path_val_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/val_caps_2.pkl'\n",
    "path_val_c = f'/data/admitosstorage/Phase_2/data_phase2/Combined/val_caps_3.pkl'\n",
    "\n",
    "with open(path_val_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_captions1, f)\n",
    "\n",
    "with open(path_val_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_captions2, f)\n",
    "\n",
    "with open(path_val_c, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_captions3, f)\n",
    "    \n",
    "path_test_a = f'/data/admitosstorage/Phase_2/data_phase2/Combined/test_caps_1.pkl'\n",
    "path_test_b = f'/data/admitosstorage/Phase_2/data_phase2/Combined/test_caps_2.pkl'\n",
    "path_test_c = f'/data/admitosstorage/Phase_2/data_phase2/Combined/test_caps_3.pkl'\n",
    "\n",
    "with open(path_test_a, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_captions1, f)\n",
    "\n",
    "with open(path_test_b, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_captions2, f)\n",
    "\n",
    "with open(path_test_c, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_captions3, f)\n",
    "\n",
    "path_train_stories = f'/data/admitosstorage/Phase_2/data_phase2/Combined/train_stories.pkl'\n",
    "path_val_stories = f'/data/admitosstorage/Phase_2/data_phase2/Combined/val_stories.pkl'\n",
    "path_test_stories = f'/data/admitosstorage/Phase_2/data_phase2/Combined/test_stories.pkl'\n",
    "\n",
    "with open(path_train_stories, 'wb') as f:\n",
    "    pickle.dump(tokenized_train_stories, f)\n",
    "\n",
    "with open(path_val_stories, 'wb') as f:\n",
    "    pickle.dump(tokenized_val_stories, f)\n",
    "\n",
    "with open(path_test_stories, 'wb') as f:\n",
    "    pickle.dump(tokenized_test_stories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f123236-4592-4324-bc6d-f7f802b5fe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10fcb4-7ada-4403-924f-0368b93071ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082d8ee-40b1-4bd7-bdeb-0e8ea00468f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b40ec8-c882-4495-927e-e14fca37bbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59ff188-b25d-4f46-bd3f-b3f46d418b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE USED:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apassadaki/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from t4 import T4Transformer\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "my_device = torch.device('cuda:0') if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE USED: \", my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e26bda-58f0-45e5-b0ed-99fc9da35f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522 30522\n",
      "Okay with loading the model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocabulary_size_input = len(tokenizer.vocab) # BERT's vocabulary size\n",
    "vocabulary_size_target = len(tokenizer.vocab) # BERT's vocabulary size\n",
    "print(vocabulary_size_input, vocabulary_size_target)\n",
    "embedding_dim = 512\n",
    "number_layers = 6\n",
    "number_heads = 8\n",
    "feed_forward_dim = 2048\n",
    "model = T4Transformer(vocab_size_input=vocabulary_size_input, vocab_size_target=vocabulary_size_target, d_model=embedding_dim, num_layers=number_layers, \n",
    "                        num_heads=number_heads, d_ff=feed_forward_dim, dropout=0.15, pad_token=0, device=my_device, name=None)\n",
    "model.load_state_dict(torch.load(f'/data/admitosstorage/Phase_2/trained_models/seq/model_t4_combined_e3.pt', map_location=my_device))\n",
    "model.eval()\n",
    "model = model.to(my_device)\n",
    "print(\"Okay with loading the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf534010-3d95-4866-b12c-17af8a49b70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tall, barren tree by a flowing creek. [SEP] A fallen tree trunk on a broken wood bridge. [SEP] The iron gate of a small palace with shrubs on the side. [SEP] Perpendicular plants are standing straight out of a muddy ground. [SEP] An outdoor shot showing a river up around leafless trees.\n",
      "The swamp had started as an upsetting stream of dead fishes, flies, and frogs. After having made it across the wobbly bridge. I finally got to the house just beyond the marsh. Even before that I walked through the suffocating swamp. I had to cross the creepy lake.\n",
      "tensor([[  101,  1037,  4206,  1010, 20225,  3392,  2011,  1037,  8577,  3636,\n",
      "          1012,   102,  1037,  5357,  3392,  8260,  2006,  1037,  3714,  3536,\n",
      "          2958,  1012,   102,  1996,  3707,  4796,  1997,  1037,  2235,  4186,\n",
      "          2007, 18812,  2006,  1996,  2217,  1012,   102, 19581,  4264,  2024,\n",
      "          3061,  3442,  2041,  1997,  1037, 15405,  2598,  1012,   102,  2019,\n",
      "          7254,  2915,  4760,  1037,  2314,  2039,  2105,  7053,  3238,  3628,\n",
      "          1012,   102]], device='cuda:0')\n",
      "tensor([[  101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,  5460,\n",
      "          1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,  2044,\n",
      "          2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,  1045,\n",
      "          2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,  1012,\n",
      "          2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246, 27483,\n",
      "         11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109,  2697,  1012,\n",
      "           102]])\n"
     ]
    }
   ],
   "source": [
    "new_entry = (['A tall, barren tree by a flowing creek.',\n",
    "   'A fallen tree trunk on a broken wood bridge.',\n",
    "   'The iron gate of a small palace with shrubs on the side.',\n",
    "   'Perpendicular plants are standing straight out of a muddy ground.',\n",
    "   'An outdoor shot showing a river up around leafless trees.'],\n",
    "  'The swamp had started as an upsetting stream of dead fishes, flies, and frogs. After having made it across the wobbly bridge. I finally got to the house just beyond the marsh. Even before that I walked through the suffocating swamp. I had to cross the creepy lake.')\n",
    "\n",
    "new_captions = new_entry[0]\n",
    "new_story = new_entry[1]\n",
    "input_text = ' [SEP] '.join(new_captions)\n",
    "print(input_text)\n",
    "print(new_story)\n",
    "caption_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "target_ids = tokenizer(new_story, return_tensors=\"pt\").input_ids\n",
    "caption_ids = caption_ids.to(my_device)\n",
    "print(caption_ids)\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8a8b1d-1a7e-476a-9d53-f9bd4881f020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 30522])\n",
      "tensor([[101]], device='cuda:0')\n",
      "gen step: 0 --> tensor([[101, 101]], device='cuda:0')\n",
      "torch.Size([1, 2, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 1 --> tensor([[ 101,  101, 1996]], device='cuda:0')\n",
      "torch.Size([1, 3, 30522])\n",
      "tensor([[11963]], device='cuda:0')\n",
      "gen step: 2 --> tensor([[  101,   101,  1996, 11963]], device='cuda:0')\n",
      "torch.Size([1, 4, 30522])\n",
      "tensor([[2018]], device='cuda:0')\n",
      "gen step: 3 --> tensor([[  101,   101,  1996, 11963,  2018]], device='cuda:0')\n",
      "torch.Size([1, 5, 30522])\n",
      "tensor([[2318]], device='cuda:0')\n",
      "gen step: 4 --> tensor([[  101,   101,  1996, 11963,  2018,  2318]], device='cuda:0')\n",
      "torch.Size([1, 6, 30522])\n",
      "tensor([[2004]], device='cuda:0')\n",
      "gen step: 5 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004]], device='cuda:0')\n",
      "torch.Size([1, 7, 30522])\n",
      "tensor([[2019]], device='cuda:0')\n",
      "gen step: 6 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 8, 30522])\n",
      "tensor([[6314]], device='cuda:0')\n",
      "gen step: 7 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 9, 30522])\n",
      "tensor([[3436]], device='cuda:0')\n",
      "gen step: 8 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10, 30522])\n",
      "tensor([[5460]], device='cuda:0')\n",
      "gen step: 9 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460]], device='cuda:0')\n",
      "torch.Size([1, 11, 30522])\n",
      "tensor([[1997]], device='cuda:0')\n",
      "gen step: 10 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997]], device='cuda:0')\n",
      "torch.Size([1, 12, 30522])\n",
      "tensor([[2757]], device='cuda:0')\n",
      "gen step: 11 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757]], device='cuda:0')\n",
      "torch.Size([1, 13, 30522])\n",
      "tensor([[21995]], device='cuda:0')\n",
      "gen step: 12 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995]], device='cuda:0')\n",
      "torch.Size([1, 14, 30522])\n",
      "tensor([[1010]], device='cuda:0')\n",
      "gen step: 13 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010]], device='cuda:0')\n",
      "torch.Size([1, 15, 30522])\n",
      "tensor([[10029]], device='cuda:0')\n",
      "gen step: 14 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029]], device='cuda:0')\n",
      "torch.Size([1, 16, 30522])\n",
      "tensor([[1010]], device='cuda:0')\n",
      "gen step: 15 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010]], device='cuda:0')\n",
      "torch.Size([1, 17, 30522])\n",
      "tensor([[1998]], device='cuda:0')\n",
      "gen step: 16 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 18, 30522])\n",
      "tensor([[17582]], device='cuda:0')\n",
      "gen step: 17 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 19, 30522])\n",
      "tensor([[1012]], device='cuda:0')\n",
      "gen step: 18 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 20, 30522])\n",
      "tensor([[2044]], device='cuda:0')\n",
      "gen step: 19 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044]], device='cuda:0')\n",
      "torch.Size([1, 21, 30522])\n",
      "tensor([[2383]], device='cuda:0')\n",
      "gen step: 20 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383]], device='cuda:0')\n",
      "torch.Size([1, 22, 30522])\n",
      "tensor([[2081]], device='cuda:0')\n",
      "gen step: 21 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081]], device='cuda:0')\n",
      "torch.Size([1, 23, 30522])\n",
      "tensor([[2009]], device='cuda:0')\n",
      "gen step: 22 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009]], device='cuda:0')\n",
      "torch.Size([1, 24, 30522])\n",
      "tensor([[2408]], device='cuda:0')\n",
      "gen step: 23 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408]], device='cuda:0')\n",
      "torch.Size([1, 25, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 24 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996]], device='cuda:0')\n",
      "torch.Size([1, 26, 30522])\n",
      "tensor([[24185]], device='cuda:0')\n",
      "gen step: 25 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185]], device='cuda:0')\n",
      "torch.Size([1, 27, 30522])\n",
      "tensor([[24200]], device='cuda:0')\n",
      "gen step: 26 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 28, 30522])\n",
      "tensor([[2958]], device='cuda:0')\n",
      "gen step: 27 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 29, 30522])\n",
      "tensor([[1012]], device='cuda:0')\n",
      "gen step: 28 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 30, 30522])\n",
      "tensor([[1045]], device='cuda:0')\n",
      "gen step: 29 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045]], device='cuda:0')\n",
      "torch.Size([1, 31, 30522])\n",
      "tensor([[2633]], device='cuda:0')\n",
      "gen step: 30 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633]], device='cuda:0')\n",
      "torch.Size([1, 32, 30522])\n",
      "tensor([[2288]], device='cuda:0')\n",
      "gen step: 31 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288]], device='cuda:0')\n",
      "torch.Size([1, 33, 30522])\n",
      "tensor([[2000]], device='cuda:0')\n",
      "gen step: 32 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000]], device='cuda:0')\n",
      "torch.Size([1, 34, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 33 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996]], device='cuda:0')\n",
      "torch.Size([1, 35, 30522])\n",
      "tensor([[2160]], device='cuda:0')\n",
      "gen step: 34 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160]], device='cuda:0')\n",
      "torch.Size([1, 36, 30522])\n",
      "tensor([[2074]], device='cuda:0')\n",
      "gen step: 35 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074]], device='cuda:0')\n",
      "torch.Size([1, 37, 30522])\n",
      "tensor([[3458]], device='cuda:0')\n",
      "gen step: 36 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 38, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 37 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 39, 30522])\n",
      "tensor([[9409]], device='cuda:0')\n",
      "gen step: 38 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 40, 30522])\n",
      "tensor([[1012]], device='cuda:0')\n",
      "gen step: 39 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012]], device='cuda:0')\n",
      "torch.Size([1, 41, 30522])\n",
      "tensor([[2130]], device='cuda:0')\n",
      "gen step: 40 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130]], device='cuda:0')\n",
      "torch.Size([1, 42, 30522])\n",
      "tensor([[2077]], device='cuda:0')\n",
      "gen step: 41 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077]], device='cuda:0')\n",
      "torch.Size([1, 43, 30522])\n",
      "tensor([[2008]], device='cuda:0')\n",
      "gen step: 42 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008]], device='cuda:0')\n",
      "torch.Size([1, 44, 30522])\n",
      "tensor([[1045]], device='cuda:0')\n",
      "gen step: 43 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045]], device='cuda:0')\n",
      "torch.Size([1, 45, 30522])\n",
      "tensor([[2939]], device='cuda:0')\n",
      "gen step: 44 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939]], device='cuda:0')\n",
      "torch.Size([1, 46, 30522])\n",
      "tensor([[2083]], device='cuda:0')\n",
      "gen step: 45 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083]], device='cuda:0')\n",
      "torch.Size([1, 47, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 46 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 48, 30522])\n",
      "tensor([[10514]], device='cuda:0')\n",
      "gen step: 47 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 49, 30522])\n",
      "tensor([[4246]], device='cuda:0')\n",
      "gen step: 48 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 50, 30522])\n",
      "tensor([[5001]], device='cuda:0')\n",
      "gen step: 49 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001]], device='cuda:0')\n",
      "torch.Size([1, 51, 30522])\n",
      "tensor([[11963]], device='cuda:0')\n",
      "gen step: 50 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963]], device='cuda:0')\n",
      "torch.Size([1, 52, 30522])\n",
      "tensor([[1012]], device='cuda:0')\n",
      "gen step: 51 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012]], device='cuda:0')\n",
      "torch.Size([1, 53, 30522])\n",
      "tensor([[1045]], device='cuda:0')\n",
      "gen step: 52 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045]], device='cuda:0')\n",
      "torch.Size([1, 54, 30522])\n",
      "tensor([[2018]], device='cuda:0')\n",
      "gen step: 53 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018]], device='cuda:0')\n",
      "torch.Size([1, 55, 30522])\n",
      "tensor([[2000]], device='cuda:0')\n",
      "gen step: 54 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000]], device='cuda:0')\n",
      "torch.Size([1, 56, 30522])\n",
      "tensor([[2892]], device='cuda:0')\n",
      "gen step: 55 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892]], device='cuda:0')\n",
      "torch.Size([1, 57, 30522])\n",
      "tensor([[1996]], device='cuda:0')\n",
      "gen step: 56 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892,  1996]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 58, 30522])\n",
      "tensor([[17109]], device='cuda:0')\n",
      "gen step: 57 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 59, 30522])\n",
      "tensor([[2697]], device='cuda:0')\n",
      "gen step: 58 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109,  2697]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 60, 30522])\n",
      "tensor([[1012]], device='cuda:0')\n",
      "gen step: 59 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109,  2697,\n",
      "          1012]], device='cuda:0')\n",
      "torch.Size([1, 61, 30522])\n",
      "tensor([[102]], device='cuda:0')\n",
      "gen step: 60 --> tensor([[  101,   101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,\n",
      "          5460,  1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,\n",
      "          2044,  2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,\n",
      "          1045,  2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,\n",
      "          1012,  2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,\n",
      "          5001, 11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109,  2697,\n",
      "          1012,   102]], device='cuda:0')\n",
      "tensor([[  101,  1996, 11963,  2018,  2318,  2004,  2019,  6314,  3436,  5460,\n",
      "          1997,  2757, 21995,  1010, 10029,  1010,  1998, 17582,  1012,  2044,\n",
      "          2383,  2081,  2009,  2408,  1996, 24185, 24200,  2958,  1012,  1045,\n",
      "          2633,  2288,  2000,  1996,  2160,  2074,  3458,  1996,  9409,  1012,\n",
      "          2130,  2077,  2008,  1045,  2939,  2083,  1996, 10514,  4246,  5001,\n",
      "         11963,  1012,  1045,  2018,  2000,  2892,  1996, 17109,  2697,  1012,\n",
      "           102]], device='cuda:0')\n",
      "the swamp had started as an upsetting stream of dead fishes, flies, and frogs. after having made it across the wobbly bridge. i finally got to the house just beyond the marsh. even before that i walked through the suff lap swamp. i had to cross the creepy lake.\n"
     ]
    }
   ],
   "source": [
    "# Generate narrative story\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(caption_ids, target_ids, tokenizer)\n",
    "    print(generated_ids)\n",
    "story = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a917991-9736-48bb-b1e6-bda14a459fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
